\section{Introduction}
When working on large datasets, finding and selecting the interesting pieces of
the data can be a cumbersome process. Currently, the HDF5 library enables the 
application developer to select, read and write data but does not provide any 
mechanism to select and retrieve pieces without prior knowledge of its
content, or without the developer to provide the exact data coordinates that
he is willing to access. To satisfy that need, one must be able
to issue queries by specifying a data selection criteria. These queries,
applied to the data, can then generate a selection, which in turn contains a
set of coordinates
satisfying the query. However, generating a selection may actually imply accessing the
data. To accelerate and facilitate that
process (i.e., so that the actual data no longer needs to be accessed), one can
also generate indexes and use these indexes
to directly answer the specified query, by finding the coordinates of the matching
elements directly from the index.

We define in this RFC the components that can enable application developers to
create complex and high-performance queries on both metadata and data elements
within an HDF5 container and retrieve the results of applying those query
operations. Support for these operations can be defined via:
\begin{itemize}
\item New \textit{query} objects\footnote{Query objects are
\textit{in-memory} objects, which therefore do not modify the content of the
container.\label{fn:object}} and API routines, enabling the construction of
query requests for execution on HDF5 containers;
\item New \textit{index} objects and API routines, which allows the creation of
indexes on the contents of HDF5 containers, to improve query performance.
\end{itemize}

\section{Query Objects}
Query objects are the foundation of the data analysis operations in HDF5 and
can be built up from simple components in a programmatic way to create complex
operations using \textit{Boolean} operations. The current API is presented
below:

{\lstsetc
\begin{lstlisting}
hid_t  H5Qcreate(H5Q_type_t query_type, H5Q_match_op_t match_op, ...);
herr_t H5Qclose(hid_t query_id);
hid_t  H5Qcombine(hid_t query1_id, H5Q_combine_op_t combine_op, hid_t query2_id);
herr_t H5Qget_type(hid_t query_id, H5Q_type_t *query_type);
herr_t H5Qget_match_op(hid_t query_id, H5Q_match_op_t *match_op);
herr_t H5Qget_components(hid_t query_id, hid_t *subquery1_id, hid_t *subquery2_id);
herr_t H5Qget_combine_op(hid_t query_id, H5Q_combine_op_t *op_type);
herr_t H5Qencode(hid_t query_id, void *buf, size_t *nalloc);
hid_t  H5Qdecode(const void *buf);
\end{lstlisting}
}

\subsection{Query Creation}

The core query API is composed of
two routines: \texttt{H5Qcreate} and \texttt{H5Qcombine}. \texttt{H5Qcreate}
creates new queries, by specifying an aspect of an HDF5 container, such as:
\begin{itemize}
\item \texttt{H5Q\_TYPE\_DATA\_ELEM} (data element);
\item \texttt{H5Q\_TYPE\_LINK\_NAME} (link name);
\item \texttt{H5Q\_TYPE\_ATTR\_NAME} (attribute name);
\item \texttt{H5Q\_TYPE\_ATTR\_VALUE} (attribute value);
\end{itemize}
as well as a match operator, such as:
\begin{itemize}
\item \texttt{H5Q\_MATCH\_EQUAL} ($=$);
\item \texttt{H5Q\_MATCH\_NOT\_EQUAL} ($\neq$);
\item \texttt{H5Q\_MATCH\_LESS\_THAN} ($\leq$);
\item \texttt{H5Q\_MATCH\_GREATER\_THAN} ($\geq$);
\end{itemize}
and a value for the match operator.
Created query objects can be serialized and deserialized using the \texttt{H5Qencode}
and \texttt{H5Qdecode} routines\footnote{Serialization/deserialization of queries
were introduced so that queries can be sent through the network.}, and their
content can be retrieved using the corresponding accessor routines.
\texttt{H5Qcombine} combines two query objects into a
new query object, using boolean operators such as:
\begin{itemize}
\item \texttt{H5Q\_COMBINE\_AND} ($\mathrm{\land}$);
\item \texttt{H5Q\_COMBINE\_OR} ($\mathrm{\lor}$).
\end{itemize}
Queries created with \texttt{H5Qcombine} can be used as input to further
calls to \texttt{H5Qcombine}, creating more complex queries.
For example, a single call to \texttt{H5Qcreate} could create a query object
that would match data elements in any dataset within the container that are
equal to the value ``$\mathrm{17}$''. Another call to \texttt{H5Qcreate} could create a
query object that would match link names equal to ``$\mathrm{Pressure}$''.
Calling \texttt{H5Qcombine} with the $\mathrm{\land}$ operator and those two query
objects would create a new query object that matched elements equal to ``$\mathrm{17}$''
in HDF5 datasets with link names equal to ``$\mathrm{Pressure}$''.
Creating the data analysis extensions to HDF5 using a \textit{programmatic
interface} for defining queries avoids defining a text-based query language
as a core component of the data analysis interface, and is more in keeping with
the design and level of abstraction of the HDF5 API.
The HDF5 data model is more complex than traditional database tables and a
simpler query model would likely not be able to express the kinds of queries
needed to extract the full set of components of an HDF5 container. A text-based
query language (or GUI) could certainly be built on top of the query API
defined here to provide a more user-friendly (as opposed to
\textit{developer-friendly}) query syntax like ``$\mathrm{Pressure = 17}$''.
However, we regard this as out-of-scope for now.

\subsection{Query Execution and Views}
Applying a query to an HDF5 container creates an HDF5 \textit{view}. A view is
an anonymous HDF5 group created in a temporary memory container. A view group contains up to
three 1-D dataset objects with references into the contents of the HDF5 container
that the query was applied to:
one with \textit{object} references, one with \textit{region} references and
one with \textit{attribute} references.

\begin{figure}
\input{pics/hdf5_view}
\caption{Temporary memory container with datasets containing query results (i.e.,
HDF5 references).}
\label{fig:hdf5_view}
\vspace{-20pt}
\end{figure}

A new view is created by the
following \texttt{H5Qapply} routine, which applies a query to an HDF5 container,
group hierarchy, or individual object and returns the object ID of the newly created
group. The attributes, objects, and/or data regions referenced within a view's
datasets can be retrieved by further HDF5 dataset (\texttt{H5D*}) API calls.

{\lstsetc
\begin{lstlisting}
hid_t H5Qapply(hid_t loc_id, hid_t query_id, unsigned *result, hid_t vcpl_id);
\end{lstlisting}
}

Although the created view is stored in memory, it can be persisted
by calling \texttt{H5Ocopy()} to copy the group (stored in a virtual
container) to a persistent container. For
coherency, a time stamp may also be attached to it so that its states has a meaning
compared to the state of the container that the query was applied to (as the
container may have been modified in the meantime). It may be useful in
the future to define different states to the view (\textit{dead} or
\textit{live}) so that the user knows whether the view is current or not.

%To further ease the retrieval of the results from the view and for convenience,
%an API specific to the view object may be defined:

%\note[JS]{Which ones do we really need???}
%{\lstsetc
%\begin{lstlisting}
%herr_t H5Vget_location(hid_t view_id, hid_t *loc_id);
%herr_t H5Vget_query(hid_t view_id, hid_t *query_id);
%herr_t H5Vget_counts(hid_t view_id, hsize_t *attr_count, hsize_t *obj_count,
%  hsize_t *elem_region_count);
%herr_t H5Vget_attrs(hid_t view_id, hsize_t start, hsize_t count, hid_t attr_id[]);
%herr_t H5Vget_objs(hid_t view_id, hsize_t start, hsize_t count, hid_t obj_id[]);
%herr_t H5Vget_elem_regions(hid_t view_id, hsize_t start, hsize_t count,
%  hid_t dataset_id[], hid_t dataspace_id[]);
%\end{lstlisting}
%}

%Note that currently, attribute references are not available, this feature will be added in order to
%support views that contain attribute references\footnote{See RFC 201X-XX-XX.vX.}.

For example, starting with the HDF5 container described in~\FigureRef{fig:hdf5_view1},
applying a ``$\mathrm{link\_name}$ $\mathrm{=}$ $\mathrm{Pressure}$''
query would result in the view shown in~\FigureRef{fig:hdf5_view2}, highlighted in blue.
\begin{figure}
\begin{subfigure}[b]{.49\linewidth}
\centering
\resizebox{\textwidth}{!}{
  \input{pics/hdf5_view1}
}
\caption{HDF5 container example.}
\label{fig:hdf5_view1}
\end{subfigure}
\hfill
\begin{subfigure}[b]{.49\linewidth}
\centering
\resizebox{\textwidth}{!}{
  \input{pics/hdf5_view2}
}
\caption{HDF5 container with link name query applied.}
\label{fig:hdf5_view2}
\end{subfigure}
\caption{HDF5 view creation example with simple query.}
\end{figure}

Alternatively, applying a ``$\mathrm{data\_element}$ $\mathrm{=}$ $\mathrm{17}$''
query would result in the view shown in~\FigureRef{fig:hdf5_view3}, highlighted in blue.
Finally, applying the combined queries ``$\mathrm{(link\_name = Pressure)}$
$\mathrm{\land}$ $\mathrm{(data\_element = 17)}$''
would result in the view shown in~\FigureRef{fig:hdf5_view4}, highlighted in blue.

\begin{figure}
\begin{subfigure}[b]{.49\linewidth}
\centering
\resizebox{\textwidth}{!}{
  \input{pics/hdf5_view3}
}
\caption{HDF5 container with data element query applied.}
\label{fig:hdf5_view3}
\end{subfigure}
\hfill
\begin{subfigure}[b]{.49\linewidth}
\centering
\resizebox{\textwidth}{!}{
  \input{pics/hdf5_view4}
}
\caption{HDF5 container with combined query applied.}
\label{fig:hdf5_view4}
\end{subfigure}
\caption{HDF5 view creation example with combined query.}
\vspace{-20pt}
\end{figure}

Since views contain a set of HDF5 references (object,
dataset region or attribute references) to components of the underlying
container, they retain the context of the original container. For example, the
view containing the results in~\FigureRef{fig:hdf5_view4} will contain three
dataset region references, which
can be retrieved from the view object and probed for the dataset and selection
containing the elements that match the query with the existing \texttt{H5Rdereference}
and \texttt{H5Rget\_region} API calls. Note that selections returned from a region
reference retain the underlying dataset's dimensionality and coordinates---they
are not \textit{flattened} into a 1-D series of elements. The selection returned
from a region reference can also be applied to a different dataset in the container,
allowing a query on pressure values to be used to extract temperature values,
for example.

\TableRef{tab:querycomb} describes the result types for atomic queries and
combining queries of different types. Query results of \textit{None} type are rejected
when \texttt{H5Qcombine} is called, causing it to return failure\footnote{Query
results of \textit{None} type may be implemented with another result type in the
future, once experience with the query framework is acquired and a meaningful
grammar for those results are defined.}.

\begin{longtable}{ll}
\vspace{-30pt}\\
\caption{Query combinations and associated result reference type.}\\
\label{tab:querycomb} \vspace{-10pt} \\
\toprule
Query & Result Type\\ \midrule
\endfirsthead
\toprule
Query & Result Type\\ \midrule
\endhead
\multicolumn{2}{c}{\ldots}\\
\bottomrule
\endfoot
\bottomrule
\endlastfoot
\texttt{H5Q\_TYPE\_DATA\_ELEM} & Dataset~Region \\
\texttt{H5Q\_TYPE\_ATTR\_VALUE} & Attribute \\
\texttt{H5Q\_TYPE\_ATTR\_NAME} & Attribute \\
\texttt{H5Q\_TYPE\_LINK\_NAME} & Object \\
Dataset~Element $\mathrm{\land}$ Dataset~Element & Dataset~Region \\
Dataset~Element $\mathrm{\land}$ Attribute & Dataset~Region \\
Dataset~Element $\mathrm{\land}$ Object & Dataset~Region \\
Attribute $\mathrm{\land}$ Attribute & Attribute \\
Attribute $\mathrm{\land}$ Object & Object \\
Object $\mathrm{\land}$ Object & Object \\
Dataset~Element $\mathrm{\lor}$ Dataset~Element & Dataset~Region \\
Dataset~Element $\mathrm{\lor}$ Attribute & Combination \\
Dataset~Element $\mathrm{\lor}$ Object & Combination \\
Dataset~Element $\mathrm{\lor}$ Combination & Combination \\
Attribute $\mathrm{\lor}$ Attribute & Attribute \\
Attribute $\mathrm{\lor}$ Object & Combination \\
Attribute $\mathrm{\lor}$ Combination & Combination \\
Object $\mathrm{\lor}$ Object & Object \\
Object $\mathrm{\lor}$ Combination & Combination \\
Combination $\mathrm{\lor}$ Combination & Combination \\
Combination $\mathrm{\land}$ Dataset~Element & None \\
Combination $\mathrm{\land}$ Attribute & None \\
Combination $\mathrm{\land}$ Object & None \\
Combination $\mathrm{\land}$ Combination & None \\
\end{longtable}

\subsection{Cross Container Queries}

In the case where multiple containers (files, locations) need to be queried,
a single query operation may be used instead of performing individual queries
on each container. Performing queries across multiple containers with a single
operation can enable analysis operations to generate an aggregated
view of query results more easily, as well as enable a silent execution of the
query in parallel, thereby reducing the time to generate a view from multiple containers.

The first extension to the previously described \texttt{H5Qapply} call is defined
with the following routine, \texttt{H5Qapply\_multi}:

{\lstsetc
\begin{lstlisting}
hid_t H5Qapply_multi(size_t loc_count, hid_t loc_ids[], hid_t query_id,
  unsigned *result, hid_t vcpl_id);
\end{lstlisting}
}

Location IDs specified may be entire containers, groups in a container's hierarchy
or individual datasets within a container. These locations may reside within the
same container, or in multiple containers.
Applying cross-container queries creates a view that contains references
to external locations (as opposed to the previous \texttt{H5Qapply} call where
references were internal). Therefore, the extended HDF5 reference object
also includes a container identifier so that, when the view result is
given back to the user, a subsequent call to \texttt{H5Rdereference} can return
a reference to an object within an externally referenced container\footnote{
Please refer to the H5R reference RFC.}.

%Additionally, the \texttt{H5Qapply\_str}
%routine allows the user to provide container names instead of HDF5 locations:
%{\lstsetc
%\begin{lstlisting}
%hid_t H5Qapply_str(size_t cont_count, const char *cont_name[], hid_t query_id,
%  unsigned *result, hid_t vcpl_id);
%\end{lstlisting}
%}
%As a direct consequence, one may want to pass queries that match a particular
%container name. Therefore the \texttt{H5Q\_TYPE\_CONT\_NAME} query type can be
%used to construct a query that matches this new condition. The matching
%condition may be passed in the form of a file name or a regular
%expression.
%(Optional?) Apply query on all the containers of a given directory with \texttt{H5Qapply\_dir}
%{\lstsetc
%\begin{lstlisting}
%hid_t H5Qapply_dir(const char *path, hid_t query_id, unsigned *result, hid_t vcpl_id);
%\end{lstlisting}
%}

%Parallel execution of the query optional? \textit{Pass hint for parallel execution
%through property list.}

\section{Index Objects}
Index objects are designed to accelerate creation of views from query operations.
For example, if the previously described ``$\mathrm{(link\_name = Pressure)}$
$\mathrm{\land}$ $\mathrm{(data\_element = 17)}$'' query
is going to be either frequently executed or executed
on a container that contains significantly large datasets, indexes
could be created in that container, which would speed up the
creation of views when querying for link names and for data element values.
Indexes created for accelerating the  ``$\mathrm{(link\_name = Pressure)}$'' or
``$\mathrm{(data\_element}$ $\mathrm{= 17)}$'' queries
would also improve view creation for the more complex
``$\mathrm{(link\_name = Pressure)}$ $\mathrm{\land}$
$\mathrm{(data\_element = 17)}$'' query.
We distinguish two different types of indexes: \textit{data} indexes and
\textit{metadata} indexes. Data indexes apply to dataset elements, which
represent the largest volume of data in typical HPC application usage of HDF5,
whereas metadata indexes apply to link or attribute name components of the queries.

\subsection{Data Indexing}

The data indexing API can work in conjunction with the view creation. When an \texttt{H5Qapply}
call is made on a given location, an index attached to any dataset queried
for element value ranges will be used to speed up the query process and return
a dataspace selection to the library for later use.
There are different techniques for creating data element indexes, and the most
efficient method will vary depending on the type of the data that is to be
indexed, its layout, etc. A new interface for the HDF5 library that uses a
plugin mechanism is therefore defined.

\subsubsection{Indexing Interface and Plugins}

This interface is defined for adding third-party indexing plugins,
such as FastBit~\cite{Wu05}, ALACRITY~\cite{alacrity13}, etc.
The interface provides indexing plugins with efficient access to the contents of
the container for both the creation and the maintenance of indexes. In addition,
the interface allows third-party plugins to create private data structures
within the container for storing the contents of the index.
The current API as well as the plugin interface are presented below:

{\lstsetc
\begin{lstlisting}
herr_t  H5Xregister(const H5X_class_t *idx_class);
herr_t  H5Xunregister(unsigned plugin_id);
herr_t  H5Xcreate(hid_t scope_id, unsigned plugin_id, hid_t xcpl_id);
herr_t  H5Xremove(hid_t scope_id, unsigned n /* Index n to be removed */);
herr_t  H5Xget_count(hid_t scope_id, hsize_t *idx_count);
herr_t  H5Xget_info(hid_t scope_id, unsigned n, H5X_info_t *info);
hsize_t H5Xget_size(hid_t scope_id);

typedef struct {
    unsigned version;     /* Version number of the index plugin class struct */
                          /* (Should always be set to H5X_CLASS_VERSION, which
                           *  may vary between releases of HDF5 library) */
    unsigned id;          /* Index ID (assigned by The HDF Group, for now) */
    const char *idx_name; /* Index name (for debugging only, currently) */
    H5X_type_t type;      /* Type of data indexed by this plugin */

    /* Callbacks */
    union {               /* Union of callback index structures */
        H5X_data_class_t data_class;
        H5X_metadata_class_t metadata_class;
    } idx_class;
} H5X_class_t;

typedef struct {
    void *(*create)(hid_t dataset_id, hid_t xcpl_id, hid_t xapl_id,
        size_t *metadata_size, void **metadata);
    herr_t (*remove)(hid_t dataset_id, size_t metadata_size, void *metadata);
    void *(*open)(hid_t dataset_id, hid_t xapl_id, size_t metadata_size,
        void *metadata);
    herr_t (*close)(void *idx_handle);
    herr_t (*copy)(hid_t src_dataset_id, hid_t dest_dataset_id, hid_t xcpl_id,
        hid_t xapl_id, size_t src_metadata_size, void *src_metadata,
        size_t *dest_metadata_size, void **dest_metadata);
    herr_t (*pre_update)(void *idx_handle, hid_t dataspace_id, hid_t xxpl_id);
    herr_t (*post_update)(void *idx_handle, const void *buf, hid_t dataspace_id,
        hid_t xxpl_id);
    herr_t (*query)(void *idx_handle, hid_t query_id, hid_t xxpl_id,
        hid_t *dataspace_id);
    herr_t (*refresh)(void *idx_handle, size_t *metadata_size, void **metadata);
    herr_t (*get_size)(void *idx_handle, hsize_t *idx_size);
} H5X_data_class_t;
\end{lstlisting}
}

Index objects are stored in the HDF5 container that they apply to, but are not
visible in the container's group hierarchy\footnote{Plugin developers, note that
the HDF5 library's existing anonymous dataset and group creation calls can be
used to create objects in HDF5 files that are not visible in the container's
group hierarchy.}.
Instead, index objects are part of the metadata for the indexed dataset. New index
objects are created by passing an HDF5 location (group or dataset) to be indexed
and the index plugin ID to the \texttt{H5Xcreate} call.
Alternatively an index may be created at the same time as a dataset gets created
by passing a property to the dataset creation property list.
Index information (such as plugin ID and index metadata) is stored at index
creation time\footnote{Adding index information introduces a file format change.},
and when the user later calls \texttt{H5Dopen}, the plugin open
callback will retrieve this stored information and make use of the corresponding
index plugin for all subsequent operations\footnote{Note that the dataset's
index object is opened only when a query call is made on the dataset.}.
Similarly, calling \texttt{H5Dclose}
will call the plugin index close callback and close the objects used to store
the index data.

\begin{figure}
\vspace{-30pt}
\input{pics/hdf5_index}
\caption{Index information (plugin ID and metadata) is stored along the object header.}
\label{fig:hdf5_index}
\vspace{-20pt}
\end{figure}

When a call to \texttt{H5Dwrite} is made, the index plugin \texttt{pre\_update} and
\texttt{post\_update} callbacks will be triggered, allowing efficient index
update by first telling the index plugin the region that is going to be updated
with new data, and then realizing the actual index update, after the dataset
write has completed. This allows various optimization to be made, depending on
the data selection passed and the index plugin used. For example, a plugin could
store the region and defer the actual index update until the dataset is closed,
hence saving repeated index computation/update calls.

When a call to \texttt{H5Qapply} is made, the index plugin query callback will be
invoked to create a selection of elements in the dataset that match the query
parameters. Applications can also directly use the internally called
\texttt{H5Dquery} routine defined below to directly execute a query on a
particular dataset (accelerated by any index defined on the dataset),
and retrieve the selection that matches the query.

{\lstsetc
\begin{lstlisting}
hid_t H5Dquery(hid_t dset_id, hid_t space_id, hid_t query_id, hid_t xapl_id);
\end{lstlisting}
}

Because the amount of space taken by the index cannot be directly retrieved by
the user (since the datasets storing the indexes are known only by the plugin
itself), the \texttt{get\_size} callback can query the amount of space that
the index takes in the file and users may correspondingly query that information using the
\texttt{H5Xget\_size} routine.

\subsubsection{Current and future plugins}

Implementations for FastBit and ALACRITY index packages are already
present, as well as a dummy brute force indexing plugin. Early performance results
are presented in~\FigureRef{fig:indexing_perf}.

\begin{figure}
\vspace{-10pt}
\input{plots/indexing_perf}
\caption{Indexing performance.}
\label{fig:indexing_perf}
\vspace{-20pt}
\end{figure}

In the future more plugins will be added, with or without external dependency
(e.g., PyTables indexing, bitmap indexing).
To satisfy that need, dynamic plugin loading and registration will be supported,
allowing external libraries to plug to the current interface.

\subsubsection{Limitations}

There are some existing limitations in the use of indexes in the current
implementation: FastBit and ALACRITY do not support incremental updates,
an index is a shared resource for a dataset. Taken together, these conspire to
put limits on application updates to datasets with indexes.
Additionally, because FastBit and ALACRITY do not allow incremental updates to
an index, each modification to an existing index forces the index to be entirely
rebuilt. The limitation in FastBit and ALACRITY will need to be addressed in
the base packages' implementation, so that incremental updates
to their index information can be made.

\paragraph{Questions}Some questions are still open regarding the handling of indexes:
\begin{enumerate}
%\item How could an index be built and queried in parallel for a dataset that already exists?
\item How to handle index updates when the specified index plugin is not available?
\textit{In traditional databases, stored procedures are saved with the data and
therefore available at any time, but that is not the case here.
We could mark the index as out of date and rebuild the index when the plugin is
available again.}
\item How to handle index queries when the specified index plugin is not
available? \textit{We could fallback to another plugin and do a brute force query on the data.}
\end{enumerate}

\subsubsection{Support for HDF5 Compound Types (TBD)}

In a simple scenario, the HDF5 datatype used for creating the dataset can be defined
as a native and simple type. Therefore, building an index on this dataset implies
building that index from the entire dataset. However, in more complex scenarios, the
dataset may have been created by using a compound datatype, hence defining
multiple fields composed of native and simple datatypes within that same dataset.
Consequently, creating an index from that dataset requires the user to select a
particular field to be indexed, which may lead to having multiple indexes per dataset
depending on the number of fields that it contains. This can be done by passing
the \texttt{datatype\_id} of the field to be indexed to the \texttt{xcpl\_id},
the index creation property list, of the \texttt{H5Xcreate} call, which passes
it down to the plugin \texttt{create} callback. As multiple fields can be defined,
the field \texttt{datatype\_id} must be stored along with the existing metadata, within the
\texttt{idx\_info} message (see~\FigureRef{fig:hdf5_index}) so that the index
associated to the field can be retrieved at the time of the query.
When doing a query, the compound type is passed to the \texttt{H5Qcreate} call.
The corresponding index is then used and the query is passed to the \texttt{query}
callback of the plugin.

Consequently, when removing an index, one may choose to remove the index that
corresponds to a particular field. This can be achieved by calling \texttt{H5Xget\_info},
compare the datatype returned within the info structure, and pass the index number
that needs to be removed.

\subsubsection{Support for HDF5 Chunking (TBD)}

To support indexing of HDF5 chunks, we make each chunk a local \textit{sub-dataset}
of the original dataset. In that sense, handling every chunk can be seen as handling
a dataset from the indexing plugin point of view. If the dataset is chunked,
at the time of the index creation, we create a B-tree\footnote{The B-tree could also
be replaced by a map object.} (physically
stored on disk) that maps the coordinates of the chunks to the index plugin metadata.
When the \texttt{create} callback is called (by representing the chunk as
a local dataset, i.e., making the dataset layout point to the address of the chunk),
metadata information is returned and stored.
In the case of contiguous datasets, the index metadata as well as the index plugin ID is
stored within the dataset header of the index info message (see~\FigureRef{fig:hdf5_index}).
In the case of chunked datasets, multiple metadata that correspond to each index created
from each chunck may be accessed. Therefore, only the address of the B-tree that contains the 
metadata pieces for each chunk is stored in that header message and the index
metadata itself is stored in the B-tree.

When the dataset is opened and the index reopened, we can lookup the index
information in the B-tree that corresponds to each chunk and call the \texttt{open}
callback using the associated metadata.
%write
%   if (chunked)
%     modify I/O loop
Similarly, when a query is issued and needs to be answered, the chunks that
correspond to the selection passed to the \texttt{H5Dquery} call are selected
and their index is used to answer that query. The selection returned is then
added to a global selection, which is then in turn returned to the user.
Finally, when \texttt{H5Xremove} is called, the \texttt{delete} plugin callback is
invoked for each chunk, by using the index metadata information stored in the B-tree.

\subsubsection{Support for Parallel Indexing (TBD)}

An important design choice to support parallel indexing is to give as much
freedom as possible to the indexing plugin developer so that in the case when
the indexing library supports parallel indexing, it is still possible to take
advantage of it. Three options are available to support parallel indexing
from the previous interface:
\begin{itemize}
\item Let the index creation be collective. This however implies having synchronization
points, which is the main constraint.
\item Let the index creation be independent. However, creating datasets to
store the index data must be done collectively\footnote{An option could be to use
the metadata server VOL plugin but this option is not easily doable yet.}.
\item Make the index creation in two phases. One that consists of
building the index in parallel, independently, and gathering the information (index size, etc)
at the end. The other that consists of letting the dataset creation be done by a master
process, which can then let the other processes write the index data independently.
There could however be a memory constraint in this case if the index data has to
be kept in memory between these two phases (though building the index twice is not
a good solution either).
\end{itemize}

Changes in the plugin interface include passing the parallel context to the
callback (MPI communicator), which can be done by using the index access property
list.
In the case of chunked datasets, one may also want to operate on several chunks
at the same time, in parallel. This can be done by passing a list of IDs that
corresponds to each chunk to the callbacks. However, this also makes the plugin
interface more heavy.

\subsection{Metadata Indexing}

Metadata indexing accelerates HDF5 metadata query operations, improving 
the speed of data analysis operations. Currently metadata query operations
in HDF5 are performed by traversing the contents of the container specified
in the query, potentially generating a large amount of I/O and taking
significant time to create the query results. Adding a mechanism for storing
metadata indexes to HDF5 containers can accelerate query operations by avoiding
these expensive traversals, as is available for data element queries.

A metadata index is a data structure that tracks a particular aspect of an HDF5 container 
and can quickly answer queries about that aspect. For example, a metadata index can 
be created that tracks all the link names for objects in a container, updating the index 
whenever a link is added, modified or removed. This index can then be applied to 
queries on link names, avoiding a traversal over all the links for groups in the container.

\subsubsection{Indexing Interface and Plugins}

The interface for metadata indexes in HDF5 containers is modeled after the interface 
for data element indexes in HDF5, with a plugin architecture that allows new metadata 
index packages to be developed and added at application runtime, without modifications 
to the core HDF5 library.
The HDF5 library can then interact with the third-party indexes created in this manner 
through a set of callback interfaces that present query information to the
indexing package and retrieve results from it.
An HDF5 metadata index can be considered as a generic key-value store, in the
sense that for each \textit{key} that can for instance represent either a
link/attribute name and/or an attribute \textit{value}, is associated an HDF5
object ID. However, this is up to the plugin to define that mapping and its
storage organization.

{\lstsetc
\begin{lstlisting}
typedef struct {
    void *(*create)(hid_t loc_id, hid_t xcpl_id, hid_t xapl_id,
        size_t *metadata_size, void **metadata);
    herr_t (*remove)(hid_t loc_id, size_t metadata_size, void *metadata);
    void *(*open)(hid_t loc_id, hid_t xapl_id, size_t metadata_size,
        void *metadata);
    herr_t (*close)(void *idx_handle);

    herr_t (*insert_entry)(void *idx_handle, hid_t obj_id, hid_t xxpl_id);
    herr_t (*remove_entry)(void *idx_handle, hid_t obj_id, hid_t xxpl_id);
    herr_t (*query)(void *idx_handle, hid_t query_id, hid_t xxpl_id,
        size_t *obj_count, hid_t *obj_ids[]);

    herr_t (*get_size)(void *idx_handle, hsize_t *idx_size);
} H5X_metadata_class_t;
\end{lstlisting}
}

The \texttt{create}, \texttt{remove}, \texttt{open}, \texttt{close} callbacks
are similar to the data index plugins, albeit they operate on a file location and
not on a single object. The \texttt{insert\_entry}, \texttt{remove\_entry} callbacks
respectively insert/remove a referenced object from the index. Information can
be directly extracted from the object ID, depending on the metadata type that
the plugin will choose to index.
When the \texttt{query} callback is invoked, a list of object IDs that matches
the query is returned. The \texttt{get\_size} callback\footnote{Additional info
callbacks may also be added depending on the needs.} returns the size of the index.

\subsubsection{Current and future plugins}

Are considered both a MDHIM~\cite{Greenberg15} and a B-Tree based plugin to
provide metadata indexing capabilities. \textit{More details will be added
once the design for these plugins has been defined.}

\section{HDF5 and tools}

Existing HDF5 tools must be compatible and take into account the existence of
indexes in the file if there are any. For reference, the following behavior for
the tools is given:

\begin{itemize}
\item h5copy: copy
\item h5dump: report index information
\item h5ls: report index information
\item h5diff: ignore index information?
\item h5repack: copy index information / or generate index
\item h5edit: ignore index information?
\item h5toh4: ignore index information?
\item h5import: ignore index information
\end{itemize}

Additional tools for indexing data and answering queries will also be added
in the future.

\section{Usage Examples}

These basic examples aim at showing the analysis components presented so far.
We describe in these examples the query and view creation process and how to
efficiently retrieve data from a file by adding indexes.

\subsection{Query and View}
In this example, we show how one can create a query, apply that query to a file,
and retrieve data from the resulting view.

{\lstsetc
\begin{lstlisting}
#define FILENAME "test.h5"
#define DATASETNAME "Pressure"

int
main(int argc, char *argv[])
{
    hid_t t file, query, subquery1, subquery2, view;
    float subquery2_value = 3.14;
    unsigned apply_result = 0;

    /* Create file */
    file = H5Fcreate(FILENAME, H5F_ACC_TRUNC, H5P_DEFAULT, H5P_DEFAULT);

    /* Create groups / datasets / attributes / etc */

    /* Close the file */
    H5Fclose(file);

    /* Create a simple query */
    subquery1 = H5Qcreate(H5Q_TYPE_LINK_NAME, H5Q_MATCH_EQUAL, DATASETNAME);
    subquery2 = H5Qcreate(H5Q_TYPE_DATA_ELEM, H5Q_MATCH_LESS_THAN,
        H5T_NATIVE_FLOAT, &subquery2_value);
    query = H5Qcombine(subquery1, H5Q_COMBINE_AND, subquery2);

    /* Open file */
    file = H5Fopen(FILENAME, H5F_ACC_RDONLY, H5P_DEFAULT);

    /* Apply query to file */
    view = H5Qapply(file, query, &apply_result, H5P_DEFAULT)

    /* Result should contain region reference */
    if (result & H5Q_REF_REG) {
        hid_t refs, ref_type, ref_space, space;
        size_t n_refs, ref_size;
        void *ref_buf;

        /* Read region reference from view */
        refs = H5Dopen(view, H5Q_VIEW_REF_REG_NAME, H5P_DEFAULT);
        ref_type = H5Dget_type(refs);
        ref_space = H5Dget_space(refs);
        n_refs = (size_t) H5Sget_select_npoints(ref_space);
        ref_size = H5Tget_size(ref_type);
        ref_buf = malloc(n_refs * ref_size)
        H5Dread(refs, ref_type, H5S_ALL, ref_space, H5P_DEFAULT, ref_buf);
        H5Dclose(refs);
        H5Sclose(ref_space);

        /* Get selection from region reference */
        space = H5Rget_region(file, (href_t *) ref_buf);

        /* Use selection result [...] */

        /* Close selection */
        H5Sclose(space);

        /* Free reference buffer */
        free(ref_buf);
    }

    /* Close view */
    H5Gclose(view);

    /* Close queries */
    H5Qclose(query);
    H5Qclose(subquery1);
    H5Qclose(subquery2);

    /* Close the file */
    H5Fclose(file);
}
\end{lstlisting}
}

\subsection{Data Index and Data Query}
In this example, we show how one can make use of the query and
indexing APIs to efficiently retrieve a dataspace selection within a dataset.

{\lstsetc
\begin{lstlisting}
#define NTUPLES 256
#define FILENAME "test.h5"
#define DATASETNAME "Pressure"

int
main(int argc, char *argv[])
{
    float data[NTUPLES], *result;
    hsize_t dims[1] = {NTUPLES};
    hid_t t file, dataspace, dataset, dcpl, query, result_space;
    size_t result_npoints;
    int i;

    /* Initialize data */
    for(i = 0; i < NTUPLES; i++) data[i] = (float) i;

    /* Create file */
    file = H5Fcreate(FILENAME, H5F_ACC_TRUNC, H5P_DEFAULT, H5P_DEFAULT);

    /* Create the data space for the dataset */
    dataspace = H5Screate_simple(1, dims, NULL);

    /* Create and set property list to use FastBit index */
    dcpl = H5Pcreate(H5P_DATASET_CREATE);
    H5Pset_index_plugin(dcpl, H5X_PLUGIN_FASTBIT);

    /* Create dataset */
    dataset = H5Dcreate(file, DATASETNAME, H5T_NATIVE_FLOAT, dataspace,
        H5P_DEFAULT, dcpl, H5P_DEFAULT);

    /* Write dataset */
    H5Dwrite(dataset, H5T_NATIVE_FLOAT, H5S_ALL, H5S_ALL, H5P_DEFAULT, data);

    /* Close the dataset */
    H5Dclose(dataset);

    /* Close dataspace */
    H5Sclose(dataspace);

    /* Close the property */
    H5Pclose(dcpl);

    /* Close the file */
    H5Fclose(file);

    /* Create a simple query */
    query = H5Qcreate(H5Q_TYPE_DATA_ELEM, H5Q_MATCH_EQUAL, H5T_NATIVE_FLOAT,
        &query_value);

    /* Open file */
    file = H5Fopen(FILENAME, H5F_ACC_RDONLY, H5P_DEFAULT);

    /* Open dataset */
    dataset = H5Dopen(file, DATASETNAME, H5P_DEFAULT);

    /* NB. Alternatively the index can be generated on the existing dataset.
     * This, however, requires the file to be open in H5F_ACC_RDWR so that
     * the index can be stored within the file and attached to the dataset.
     * H5Xcreate(dataset, H5X_PLUGIN_FASTBIT, H5P_DEFAULT); */

    /* Use query to select elements in the dataset */
    result_space = H5Dquery(dataset, H5S_ALL, query, H5P_DEFAULT);

    /* Allocate space to read data */ 
    result_npoints = (size_t) H5Sget_select_npoints(result_space);
    result = malloc(result_npoints * sizeof(float));

    /* Read data using result_space_id */
    H5Dread(dataset, H5T_NATIVE_FLOAT, H5S_ALL, result_space,
        H5P_DEFAULT, result);

    /* Use result [...] */

    /* Free result */
    free(result);

    /* Close the dataset */
    H5Dclose(dataset);

    /* Close dataspace */
    H5Sclose(result_space);

    /* Close query */
    H5Qclose(query);

    /* Close the file */
    H5Fclose(file);
}
\end{lstlisting}
}

\subsection{Metadata Index}
In this example, we show how one can make use of the query and
indexing APIs to efficiently execute a metadata query on a file.

{\lstsetc
\begin{lstlisting}
#define FILENAME "test.h5"
#define DATASETNAME "Pressure"

int
main(int argc, char *argv[])
{
    hid_t t file, fcpl, query, view;
    unsigned apply_result = 0;

    /* Create and set property list to use B-Tree index */
    fcpl = H5Pcreate(H5P_FILE_CREATE);
    H5Pset_index_plugin(fcpl, H5X_PLUGIN_BTREE);

    /* Create file */
    file = H5Fcreate(FILENAME, H5F_ACC_TRUNC, fcpl, H5P_DEFAULT);

    /* Create groups / datasets / attributes / etc */

    /* Close the property */
    H5Pclose(fcpl);

    /* Close the file */
    H5Fclose(file);

    /* Create a simple query */
    query = H5Qcreate(H5Q_TYPE_LINK_NAME, H5Q_MATCH_EQUAL, DATASETNAME);

    /* Open file */
    file = H5Fopen(FILENAME, H5F_ACC_RDONLY, H5P_DEFAULT);

    /* NB. Alternatively the index can be generated on the existing file.
     * This, however, requires the file to be open in H5F_ACC_RDWR so that
     * the index can be stored within the file and attached to it.
     * H5Xcreate(file, H5X_PLUGIN_BTREE, H5P_DEFAULT); */

    /* Apply query to file */
    view = H5Qapply(file, query, &apply_result, H5P_DEFAULT)

    /* Use view result [...] */

    /* Close view */
    H5Gclose(view);

    /* Close query */
    H5Qclose(query);

    /* Close the file */
    H5Fclose(file);
}
\end{lstlisting}
}

%\section{Conclusion}
%Document in progress.

