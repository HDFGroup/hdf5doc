<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
        "http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
	<meta http-equiv="content-type" content="text/html; charset=utf-8">
	<meta name="generator" content="VoodooPad">
	<title>Reading or writing dataset elements</title>
		<style type="text/css">

body
{
	margin: 20px;
	color: #000;
	font-size: 16px;
	background-color: #BCCCAB;
}

.main
{
	min-width: 400px;
	border: solid 1px #aaaaaa;
	padding: 5px;
	font-family: verdana, arial, helvetica, sans-serif;
	font-size: 9pt;
	background: #fff;
	margin-top: 10px;
}

.header
{
	color: black;
	font-size: 24px;
	font-variant: small-caps;
	font-weight: bold;
	border: solid 1px #aaaaaa;
	background: #fff;
}

	
	</style>
	
	
</head>

<body>
    <div class="header" align="center">
        Reading or writing dataset elements
    </div>
    
    <div class="main">
        <style type="text/css">
p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 18.0px 'Lucida Grande'}
p.p2 {margin: 0.0px 0.0px 0.0px 0.0px; font: 18.0px 'Lucida Grande'; min-height: 21.0px}
li.li1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 18.0px 'Lucida Grande'}
span.s1 {text-decoration: underline}
ul.ul1 {list-style-type: hyphen}
</style>

<p class="p1">Performing I/O on dataset elements in one of the more complex aspects of the HDF5 library (as you might expect from an I/O library) and has multiple components and layers, which are only partially documented here.<span class="Apple-converted-space">&nbsp; </span>Each different method of storage for a dataset (contiguous, chunked, etc) is handled in a somewhat different manner, with some shared components or layers, so the common aspects are described in one section and then the special aspects of each storage method are documented in seperate sections.</p>
<p class="p2"><br></p>
<p class="p1">When an MPI application performs I/O on dataset elements, the default action is to perform independent I/O operations from each process.<span class="Apple-converted-space">&nbsp; </span>When independent I/O is performed by the MPI application, the underlying MPI-IO or MPI-POSIX VFD is eventually used to perform the read or write operation, but until that point, the I/O operation is handled identically to how I/O is handled for non-MPI applications. <span class="Apple-converted-space">&nbsp; </span>Since there are no special actions taken to use the MPI interface until the appropriate VFD is reached in this case, it is not discussed further here, except to note that under certain circumstances (described in context in other locations in this document set), a collective I/O operation may be initiated by an application, but the HDF5 library "breaks" the collective access into independent access in order to perform the I/O operation.</p>
<p class="p2"><br></p>
<p class="p1">When an MPI application has opened a file using the <a href="mpi-io%20vfd.html"><span class="s1">MPI-IO VFD</span></a>, collective I/O operations on dataset elements may be performed.<span class="Apple-converted-space">&nbsp; </span>The application must collectively create a dataset transfer property list (DXPL), call <a href="http://www.hdfgroup.org/HDF5/doc/RM/RM_H5P.html#Property-SetDxplMpio"><span class="s1">H5Pset_dxpl_mpio</span></a> on that DXPL to set the I/O transfer mode to H5FD_MPIO_COLLECTIVE, and then use that DXPL in calls to <a href="http://www.hdfgroup.org/HDF5/doc/RM/RM_H5D.html#Dataset-Read"><span class="s1">H5Dread</span></a> or <a href="http://www.hdfgroup.org/HDF5/doc/RM/RM_H5D.html#Dataset-Write"><span class="s1">H5Dwrite</span></a> in order to invoke collective I/O when accessing dataset elements.<span class="Apple-converted-space">&nbsp; </span>Collective read and write I/O operations on dataset elements are generally handled identically by the HDF5 library except for the eventual read or write call to the VFD layer and so are treated identically by this document set, unless noted in context.</p>
<p class="p2"><br></p>
<p class="p1">The actions for performing collective I/O are identical for all dataset storage types, with the correct routines to invoke for each storage method chosen by setting function pointers in the "I/O information" for the I/O operation:</p>
<ul class="ul1">
<li class="li1">&lt;set up the I/O information&gt; (H5D_ioinfo_init() in <a href="http://svn.hdfgroup.uiuc.edu/hdf5/trunk/src/H5Dio.c"><span class="s1">src/H5Dio.c</span></a>)</li>
<li class="li1">&lt;adjust the I/O information for parallel I/O&gt; (H5D_ioinfo_adjust() in <a href="http://svn.hdfgroup.uiuc.edu/hdf5/trunk/src/H5Dio.c"><span class="s1">src/H5Dio.c</span></a>)</li>
<ul class="ul1">
<li class="li1">&lt;check if collective I/O is possible from the application's buffer directly to the file&gt; (H5D_mpio_opt_possible() in <a href="http://svn.hdfgroup.uiuc.edu/hdf5/trunk/src/H5Dmpio.c"><span class="s1">src/H5Dmpio.c</span></a>)</li>
<ul class="ul1">
<li class="li1">The following conditions are evaluated by each process and the &lt;local opinion&gt; is set to false if any fail:</li>
<ul class="ul1">
<li class="li1">The application must have chosen collective I/O in the DXPL used for this I/O operation</li>
<li class="li1">There must not be any HDF5 datatype conversions necessary</li>
<li class="li1">There must not be any HDF5 "data transforms" (set with <a href="http://www.hdfgroup.org/HDF5/doc/RM/RM_H5P.html#Property-SetDataTransform"><span class="s1">H5Pset_data_transform</span></a>) to invoke during the I/O operation</li>
<li class="li1">The HDF5_MPI_OPT_TYPES environment variable must either be not set, or set to '1' (one)</li>
<li class="li1">The <a href="mpi-io%20vfd.html"><span class="s1">MPI-IO VFD</span></a> must be used (not the <a href="mpi-posix%20vfd.html"><span class="s1">MPI-POSIX VFD</span></a>)</li>
<li class="li1">A simple or scalar dataspace must be used for both the memory and file dataspaces</li>
<li class="li1">A point selection must not be used for either the memory or file dataspaces</li>
<li class="li1">The dataset's storage method must be either contiguous or chunked</li>
<li class="li1">[A configuration-dependent check whether the MPI implementation can handle "complex" derived MPI datatypes is checked and if the MPI implementation can't handle them, the selection for both the memory and file dataspaces must be "regular" (i.e. describable with a single call the <a href="http://www.hdfgroup.org/HDF5/doc/RM/RM_H5S.html#Dataspace-SelectHyperslab"><span class="s1">H5Sselect_hyperslab</span></a>()]</li>
<li class="li1">If the dataset is chunked:</li>
<ul class="ul1">
<li class="li1">There must be no I/O filters (like compression, etc) used</li>
<li class="li1">[A configuration-dependent check whether the MPI implementation can perform collective I/O operations correctly when not all processes actually perform any I/O (i.e. when the buffer count parameter to MPI_File_[read|write]_at_all is set to 0) and if the MPI implementation can't perform the I/O correctly, there must be elements accessed in at least one chunk]</li>
</ul>
</ul>
<li class="li1">MPI_Allreduce() is called with the "logical and" (MPI_LAND) operator and the &lt;local opinion&gt; of each process, to create the &lt;consensus opinion&gt; of all the processes, which is returned from this routine.</li>
</ul>
<li class="li1">If the &lt;consensus opinion&gt; evaluated to FALSE, collective I/O is "broken", and the I/O proceeds as an independent I/O operation on all processes.</li>
<li class="li1">If the &lt;consensus opinion&gt; evaluated to TRUE, collective I/O is possible and the function pointers for performing "multiple" I/O operations (i.e. I/O on vectors of &lt;offset/length/buffer&gt; tuples) is set to the appropriate parallel I/O operation callback for the dataset's storage type.<span class="Apple-converted-space">&nbsp; </span>The function pointers for "single" I/O operations is set to H5D_mpio_select_read or H5D_mpio_select_write (in <a href="http://svn.hdfgroup.uiuc.edu/hdf5/trunk/src/H5Dmpio.c"><span class="s1">src/H5Dmpio.c</span></a>).</li>
<ul class="ul1">
<li class="li1">For contiguous datasets, the "multiple" I/O operation callbacks are: H5D_contig_collective_read and H5D_contig_collective_write (in <a href="http://svn.hdfgroup.uiuc.edu/hdf5/trunk/src/H5Dmpio.c"><span class="s1">src/H5Dmpio.c</span></a>)</li>
<li class="li1">For chunked datasets, the "mutiple" I/O operation callbacks are H5D_chunk_collective_read and H5D_chunk_collective_write (in <a href="http://svn.hdfgroup.uiuc.edu/hdf5/trunk/src/H5Dmpio.c"><span class="s1">src/H5Dmpio.c</span></a>)</li>
</ul>
</ul>
<li class="li1">&lt;invoke the "multiple" I/O operation callback to perform the I/O operation (set earlier)&gt;</li>
<li class="li1">&lt;tear down the I/O information&gt;</li>
</ul>
<p class="p2"><br></p>
<p class="p1">The "multiple" I/O operations for collective I/O on each type of dataset storage method are further described here:</p>
<ul class="ul1">
<li class="li1"><a href="collective%20i_o%20on%20contiguous%20datasets.html"><span class="s1">Collective I/O on Contiguous Datasets</span></a></li>
<li class="li1"><a href="collective%20i_o%20on%20chunked%20datasets.html"><span class="s1">Collective I/O on Chunked Datasets</span></a></li>
</ul>
<p class="p2"><br></p>

    </div>
    <div class="main">
        <a href="_page_index.html">Page Index</a>
    </div>
</body>
</html>

