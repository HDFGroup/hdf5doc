<html>
<br>
============================
<ol><h3><b>
<li>Why these issues need to be faced now</u></b></h3><br><br>

Although we've been somewhat aware of differences between the way storage
space is allocated in a file and how fill-values are treated between HDF4
and HDF5 for a while, this hasn't been an especially burning problem that
needed to be dealt with. Unfortunately, there is a bug with the way that
memory for variable-length (VL) data is being leaked in the file when the
data elements are overwritten, and it is tied to these storage and
fill-value issues. <br><br>

Currently, when VL data elements are over-written in a dataset, the space
for the previous piece of VL data is not released to the file to be
re-used, it is instead leaked and not reused. Because the previous value
for the VL data would need to be read from the file dataset in order to
be properly released, it ties in with the fill-values stored in the file.
(For the current library design, since a heap ID is stored in the dataset 
for the location of the VL data, not the VL data itself, a heap ID set to 
all zeros is used to indicate that there is no VL data for a paticular 
location.  So currently, the only valid fill-value for VL data is an all 
zero value, indicating that no VL data has been stored in the heap.)<br>
<br> 
 
If fill-values are not written to the file, then there is the potential
for junk data to be read from the file as the VL data to be released and
errors to occur. Currently, the library relies on the filesystem to
zero-fill blocks allocated to the file when there is no fill-value set
for the dataset. We've already seen this assumption break down under
Win9x, where the OS does not zero-fill file blocks with zeros and users
report &quot;junk&quot; in datasets which have been created, but not
written to. <br><br>

So, VL data requires valid fill-values to be present in the file in order
to be certain that reading the VL data to be overwritten is valid and
contains the correct information to either free the previous VL data (in
the case of non-NULL valued VL data) or not to try to free the previous
VL data (for NULL valued VL data). Having junk (or the potential for
junk) in the data read from the file opens the possibility for corrupting
data in the file if that junk data is used to try to free the previous VL
data. <h3><b>
<li>How are things handled currently in HDF4 vs. HDF5?</u></b></h3>
<ol><h4><b>
<li>HDF4</u></b></h4><br>

These issues are specific to how the SD*() API functions operate in the
latest version of HDF4, other portions of the HDF4 library may operate in
different ways. Only the normal (i.e. &quot;contiguous&quot;) and chunked
storage methods are discussed, other storage methods are treated as
normal storage in HDF4.<br> 
<ol><u>
<li>Dataset Storage Allocation</u> <br>
Allocating space to store a dataset is deferred until the space is
needed. Space is only needed when non-fill-value data is written to a
dataset. This allows for very large datasets to be defined, and if they
are not written to, the file size can stay very small. This applies to
both contiguous and chunked data. <u><br><br>
<li>Fill-values</u> 
<ol><u>
<li>Metadata</u><br> 
Metadata documenting the fill-value is always written to a file.
Either the default fill-value (of zero) or the user's fill value is
written as an attribute of the dataset. <u><br>
<li>Writing</u> <br>
Fill-values are only written to the dataset or chunk when the entire
dataset or chunk is not going to be written in a single I/O request. For
example: in a contiguously stored dataset, if a hyperslab in the middle
of the dataset is written by the user (and this is the first piece of
data to be written to the dataset), fill-values are written to the
dataset and then the user's data is written in the hyperslab location.
However, if the entire dataset is going to be written in one write call,
then the fill-value writing step is skipped, since they would all be
immediately over-written with the actual data. 
Note: Writing fill-values in HDF4 can be turned off completely by a user
who either &quot;knows&quot; that they will be writing the entire dataset
in successive calls, or who doesn't care about data outside the region(s)
they are writing to in the dataset.<u><br> 
<li>Reading</u> <br>
If storage for the dataset or chunk is not allocated yet, the fill
value is used to fill the buffer to return to the application and the
file data is not read. <u>
</ol>
</ol><h4><b>
<li>HDF5</u></b></h4><br><br>

These issues apply to all datasets in HDF5. Only the contiguous and
chunked storage methods are discussed, other storage methods are treated
as contiguous storage in HDF5. 
<ol><u>
<li>Dataset Storage Allocation</u> <br><br>

Space for contiguously stored data is always allocated during the
creation of the dataset. Space for chunk stored data is allocated as
needed, when data needs to be written to the portion of the dataset that
the chunk occupies. (Except in the case of parallel I/O, where all the
chunks for a dataset are allocated at creation time also). <u>
<li>Fill-values</u> 
<ol><u>
<li>Metadata</u> <br><br>

Metadata documenting the fill-value for a dataset is only written out
if the user explicitly set a fill-value for the dataset during creation.
Although there is an implicit zero fill-value assumed for the dataset,
this is not enforced or recorded. <u>
<li>Writing</u> <br><br>

Fill-values are only written to contiguously stored data when a
dataset is created (and only if the user has set a fill-value). This
occurs regardless of how the fill-values will be overwritten by future
writes to the dataset. Fill-values for chunked storage data are somewhat 
more controlled, they are written only when data is actually written to 
a particular chunk.  (The library may also be smart enough to notice 
when an entire chunk is being written and to not write the fill-values 
in that case, this case hasn't been investigated).<u>
<li>Reading</u> <br><br>

Fill-values are only used for chunked storage datasets when an
unallocated chunk is read from. Because contiguously stored data always
allocates space in the file, the library assumes that there is always
valid data to read for contiguous data. <u>
 
</ol>
</ol>
</ol><h3><b>
<li>Suggestions for improving HDF5's behavior</u></b></h3><br><br>

We can provide user three properties to control the library.  They are
when to allocate space, when to write fill value and what value to write.
For each property, it has several values listed as follows.<br><br>

<ul>
<li>When to allocate space:
    <ol>
    <li>Early - during dataset create call. Certain VFLs like MPIO require space 		is allocated when dataset is created. </li>
    <li>Late  - during dataset write or close call.</li>
    </ol>
</li>

<li>When to write fill value:<br>
    Independent of whether space for dataset is allocated early or late,
    writing fill value should be an option that is able to be turned off
    entirely.
    <ol>
    <li>Never</li>
    <li>Allocation - fill value is written once space is allocated.</li>
    </ol> 
</li>

<li>What fill value to write:
    <ol>
    <li>Undefined - no value stored.</li>
    <li>Default   - library defined.</li>
    <li>User-defined - user chosen. </li>
    </ol>
</li>
</ul><br> 

By using these three properties, the library's behavior of fill value 
writing is listed in the table below during the dataset create-write-close 
cycle.<br><br>

<table border cellspacing=0 cellpadding=5>
  <tr>
     <th>When to allocate space</th>
     <th>When to write fill value</th>
     <th>What fill value to write</th>
     <th>Library create-write-close behavior</th>
  </tr>
  <tr>
     <td>early</td>
     <td>never</td>
     <td>-----</td>
     <td>Library allocates space when dataset is created, but never write
         fill value to dataset.</td>
  </tr>
  <tr>
     <td>late </td>
     <td>never</td>
     <td>-----</td>
     <td>Library allocates space when dataset is written to, but never 
         write fill value to dataset.</td>
  </tr>
  <tr>
     <td>-----</td>
     <td>allocation</td>
     <td>undefined</td>
     <td>Error on creating dataset, dataset not created.</td>
  </tr>
  <tr>
     <td>early</td>
     <td>allocation</td>
     <td>default or user-defined</td>
     <td>Allocate space for dataset when dataset is created.  Write fill 
         value(default or user-defined) to entire dataset.</td>
  </tr>
  <tr>
     <td>late</td>
     <td>allocation</td>
     <td>default or user-defined</td>
     <td>Doesn't allocate space for dataset until user's data value are
         written to dataset.  Write fill value to entire dataset before 
         writing user's data value.
  </tr>
</table>
----- stands for any value.<br><br>

During the H5Dread function call, the library behavior depends on whether
space has been allocated, whether fill value has been written to storage, 
how fill value is defined, and when to write fill value.<br><br>

<table border cellspacing=0 cellpadding=5>
  <tr>
     <th>Is space allocated?</th>
     <th>What is the fill value?</th>
     <th>When to write fill value?</th>
     <th>H5Dread behavior</th>
  </tr>
  <tr>
     <td rowspan=2>No</td>
     <td>undefined</td>
     <td>-----</td>
     <td>Error. Dataset doesn't exist, no data has been written, fill value
	 isn't defined.</td>
  </tr>
  <tr>
     <td>default or user-defined</td>
     <td>-----</td>
     <td>Fill user's buffer with fill value.</td>
  </tr>
  <tr>
     <td rowspan=3>Yes</td>
     <td>undefined</td>
     <td>-----</td>
     <td>Return data from storage(dataset), trash is possible.</td>
  </tr>
  <tr>
     <td>default or user-defined</td>
     <td>Never</td>
     <td>Return data from storage(dataset), trash is possible.</td>
  </tr>
  <tr>
     <td>default or user-defined</td>
     <td>allocation</td>
     <td>Return data from storage(dataset).</td>  
  </tr>
</table>
----- stands for any value.<br><br>
 
</ol><hr>
<i>QAK:1/9/02</i> </blockquote><br>
</html>
