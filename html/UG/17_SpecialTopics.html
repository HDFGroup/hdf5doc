<!doctype HTML public "-//W3C//DTD HTML 4.0 Frameset//EN">
<html>
<head>

<title>HDF5 User's Guide: Special Topics</title>

<!--(Meta)==========================================================-->


<!--(Links)=========================================================-->

<link href="ed_styles/NewUGelect.css" rel="stylesheet" type="text/css">

<!--( Begin styles definition )=====================================-->
<!--     Replaced with external stylesheet 'styles_NewUG.css'.      -->
<!--( End styles definition )=======================================-->

</head>

<body>

<!-- #BeginLibraryItem "/ed_libs/Copyright.lbi" -->
<!--
  * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *
  * Copyright by the Board of Trustees of the University of Illinois.         *
  * All rights reserved.                                                      *
  *                                                                           *
  * This file is part of HDF5.  The full HDF5 copyright notice, including     *
  * terms governing use, modification, and redistribution, is contained in    *
  * the files COPYING and Copyright.html.  COPYING can be found at the root   *
  * of the source code distribution tree; Copyright.html can be found at the  *
  * root level of an installed copy of the electronic HDF5 document set and   *
  * is linked from the top-level documents page.  It can also be found at     *
  * http://hdf.ncsa.uiuc.edu/HDF5/doc/Copyright.html.  If you do not have     *
  * access to either file, you may request a copy from hdfhelp@ncsa.uiuc.edu. *
  * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *
 -->
 <!-- #EndLibraryItem --><!--( TOC )=========================================================-->
<SCRIPT language="JavaScript">
<!--
document.writeln ('\
<table x-use-null-cells\
                align=right\
		width=240\
		cellspacing=0\
		class="tocTable">\
  <tr valign=top> \
    <td class="tocTableHeaderCell" colspan="2"> \
        <span class=TableHead>Chapter Contents</span></td>\
  </tr>\
<!-- Table Version 3 -->\
  <tr valign=top> \
    <td class="tocTableContentCell2"> \
      <a href="#Intro">1.</a></td>\
    <td class="tocTableContentCell3">\
	  <a href="#Intro">Introduction</a></td> \
  </tr>\
<!-- editingComment -- "tocTableContentCell" and "tocTableContentCell4" \
  <tr valign=top> \
    <td class="tocTableContentCell2"> \
      <a href="#NBitDatatype">2.</a></td>\
    <td class="tocTableContentCell3">\
	  <a href="#NBitDatatype">N-Bit Datatype</a></td>\
  </tr>\
  <tr valign=top> \
    <td class="tocTableContentCell2"> \
      <a href="#ScaleOffsetFilter">3.</a></td>\
    <td class="tocTableContentCell3">\
	  <a href="#ScaleOffsetFilter">Scale-Offset Filter</a></td> \
  </tr>\
\
-->\
<!-- are the table-closing cell class.\
    <td class="tocTableContentCell2"> \
-->\
  <tr valign=top> \
    <td class="tocTableContentCell"> \
      <a href="#MetadataCache">2.</a></td>\
    <td class="tocTableContentCell4">\
	  <a href="#MetadataCache">Metadata Caching in HDF5</a>\
  </td></tr>\
</table>\
')
-->
</SCRIPT>
<!--(End TOC)=======================================================-->

<!-- HEADER LEFT "HDF5 User's Guide" -->
<!-- HEADER RIGHT "HDF5 Special Topics" -->

<div align="center">
<a name="TOP">
<h2>Chapter 10<br><font size="7">HDF5 Special Topics</font></h2>
</a>
</div>

<a name="Intro">
<h3>1. Introduction</h3>
</a>


<a name="MetadataCache">
<h3>2. Metadata Caching in HDF5</h3>
</a>

<p>In the 1.6.4 release, we introduced a re-implementation of the 
  metadata cache.  That release contained an incomplete version of 
  the cache which could not be controlled via the API.  The version 
  in the 1.8 release is more mature, and includes new API calls that 
  allow the user program to configure the metadata cache both on file 
  open and at run time.

<p>From the user perspective, the most striking effect of the new 
  cache should be a large reduction in the cache memory requirements 
  when working with complex HDF5 files.

<p>Those working with such files may also notice a reduction in 
  file close time.

<p>Those working with HDF5 files with simple structure shouldn't 
  notice any particular changes in most cases.  In rare cases, 
  there may be a significant improvement in performance.

<p>The remainder of this document contains an architectural 
  overview of the old and new metadata caches, a discussion of 
  algorithms used to attempt to automatically adjust cache size 
  to circumstances, and a high level discussion of the cache 
  configuration controls.  It can be safely skipped by anyone who 
  works only with HDF5 files with relatively simple structure (i.e. 
  no huge groups, datasets with large numbers of chunks, or objects 
  with large numbers of attributes.)

<p>On the other hand, it is mandatory reading if you want to use 
  other than the default metadata cache configuration.  The 
  documentation on the metadata cache related API calls will not make 
  much sense without this background.
  
<h4>2.1 The Old Metadata Cache:</h4>

<p>The old metadata cache indexed the cache with a hash table with 
  no provision for collisions.  Instead, collisions were handled 
  by evicting the existing entry to make room for the new entry. 
  Aside from flushes, there was no other mechanism for evicting 
  entries, so the replacement policy could best be described as 
  "Evict on Collision".

<p>As a result, if two frequently used entries hashed to the same 
  location, they would evict each other regularly.  To decrease 
  the likelyhood of this situation, the default hash table size 
  was slightly more than 10,000.  However, since the size of 
  metadata entries is not bounded, and since entries were only 
  evicted on collision, this allowed the cache size to explode 
  when working with HDF5 files with complex structure.

<p>The "Evict on Collision" replacement policy also caused 
  problems with the parallel version of the HDF5 library, as a 
  collision with a dirty entry could force a write in response
  to a metadata read.  Since all metadata writes must be collective 
  in the parallel case, this caused the library to hang.  Prior 
  to the implementation of the new metadata cache, we dealt with 
  this issue by maintaining a shadow cache for dirty entries 
  evicted by a read.
  
<h4>2.2 The New Metadata Cache:</h4>

<p>The new metadata cache was designed to address the above 
  issues.  After implementation, it became evident that the 
  working set size for HDF5 files varies widely depending on 
  both structure and access pattern.  Thus it was necessary to 
  add support for cache size adjustment under either automatic 
  or user program control.

<p>Structurally, the new metadata cache can be thought of as a 
  heavily modified version of the UNIX buffer cache as described 
  in chapter three of M. J. Bach's "The Design of the UNIX Operating 
  System"  In essence the UNIX buffer cache uses a hash table with 
  chaining to index a pool of fixed-size buffers.  It uses the LRU 
  replacement policy to select candidates for eviction.

<p>Since HDF5 metadata entries are of no fixed size, and may 
  grow arbitrarily large, the size of the new metadata cache 
  cannot be controlled by setting a maximum number of entries. 
  Instead the new cache keeps a running sum of the sizes of all 
  entries, and will attempt to evict entries as necessary to stay 
  within a user specified maximum size.  At present, the LRU 
  replacement policy is the only option for selecting candidates 
  for eviction.
  
<p>Per the buffer cache, dirty entries are given two passes 
  through the LRU list before being evicted. The first time they 
  reach the end of the LRU list, they are flushed, marked as clean, 
  and moved to the head of the LRU list. When a clean entry reaches 
  the end of the LRU list, it is simply evicted if space is needed.

<p>The cache cannot evict entries that are locked, and thus it 
  will temporarily grow beyond its maximum size if there are 
  insufficient unlocked entries available for eviction.

<p>When operating in parallel, only the cache running under 
  process 0 of the file comunicator is allowed to write metadata 
  to file.  All the other caches must retain dirty metadata until 
  the process 0 cache tells them that the metadata is clean.

<p>Since all operations modifying metadata must be collective, 
  all caches see the same stream of dirty metadata.  This fact 
  is used to allow them to synchronize every n bytes of dirty 
  metadata, where n is a user configurable value that defaults 
  to 256 KB.

<p>To avoid sending the other caches messages from the future, 
  process 0 must not write any dirty entries until it reaches the 
  synchronization point.  When it reaches this point, it writes
  entries as needed, and then broadcasts the list of flushed
  entries to the other caches.  The caches on the other processes
  use this list to mark entries clean, allowing them to evict
  those entries as needed.

<p>The caches will also synchronize on a user initiated flush.

<p>To minimize overhead when running in parallel, the cache
  maintains a "clean" LRU list in addition to the regular LRU
  list.  This list contains only clean entries, and is used as 
  a source of candidates for eviction when flushing dirty entries
  is not allowed.

<p>Since flushing entries is forbidden most of the time when
  running in parallel, the caches can be forced to exceed their
  maximum sizes if they run out of clean entries to evict.

<p>To decrease the likelyhood of this event, the new cache allows
  the user to specify a minimum clean size -- which is a minimum
  total size of all the entries on the clean LRU plus all unused
  space in the cache.  Note that the clean LRU list is only
  maintained in the parallel version of the HDF5 library, and
  thus that the minimum clean size is only relevant when running
  that version.

<p>While the new metadata cache only supports the LRU replacement
  policy at present, that may change.  Support for multiple 
  replacement policies was very much in mind when the cache was 
  designed, as was the ability to switch replacement policies at 
  run time.  The situation has been complicated by the late addition 
  of the adaptive cache resizing requirement, as two of our resizing 
  algorithms piggyback on the LRU list.  However, if there is need 
  for additional replacement policies, it shouldn't be too hard to 
  implement them.
  
<!-- NEW PAGE -->
<h4>2.3 Adaptive Cache Resizing in the New Metadata Cache:</h4>

<p>As mentioned earlier, the metadata working set size for a HDF5 
  file varies wildly depending on the structure of the file and the 
  access pattern.  For example, a 2MB limit on metadata cache size 
  is excessive for an H5repack of almost all HDF5 files we have tested. 
  However, I have a file submitted by one of our users that that will 
  run a 13% hit rate with this cache size, and will lock up one of our 
  linux boxes using the old metadata cache.  Increase the new metadata 
  cache size to 4 MB, and the hit rate exceeds 99%.

<p>In this case the main culprit is a root group with more than 
  20,000 entries in it.  As a result, the root group heap exceeds 
  1 MB, which tends to crowd out the rest of the metadata in a 2 MB 
  cache

<p>This case and a number of synthetic tests convinced us that we 
  needed to modify the new metadata cache to expand and contract 
  according to need within user specified bounds.

<p>I was unable to find any previous work on this problem, so I 
  invented solutions as I went along.  If you are aware of prior 
  work, please send me references.  The closest I was able to come 
  was a group of embedded CPU designers who were turning off 
  sections of their cache to conserve power.
  
<h4>2.3.1 Increasing the Cache Size:</h4>

<p>Perhaps the most obvious heuristic for identifying cases in which 
  the cache is too small involves monitoring the hit rate.  If the hit 
  rate is low for a while, and the cache is at its maximum size, the 
  cache is probably too small.

<p>The hit rate threshold algorithm for increasing cache size 
  applies this intuition directly.

<p>Hit rate statistics are collected over a user specified number 
  of cache accesses.  This period is known as an epoch.

<p>At the end of each epoch, the hit rate is computed, and the 
  counters are reset.  If the hit rate is below a user specified 
  threshold and the cache is at its maximum size, the maximum size of 
  the cache is increased by a user specified multiple.  If required, 
  the new cache maximum size is clipped to stay within the user 
  specified upper bound, and optionally, within a user specified 
  maximum increment.

<p>My tests indicate that this algorithm works well in most cases. 
  However, in a synthetic test in which hit rate increased slowly with 
  cache size, and load remained steady for many epochs, I observed a 
  case in which cache size increased until hit rate just exceeded 
  the specified minimum and then stalled.

<p>If this case occurs frequently in actual use, I will have to 
  come up with an improved cache size increase algorithm.  Please let 
  me know if you see this behavior.  However, I had to work rather 
  hard to create it in my synthetic tests, so I would expect it to 
  be uncommon.
  
<h4>2.3.2 Decreasing the Cache Size:</h4>

<p>Identifying cases in which the maximum cache size is larger than 
  necessary turned out to be more difficult.
  
<h4>2.3.2.1 Hit Rate Threshold Cache Size Reduction</h4>

<p>One obvious heuristic is to monitor the hit rate and guess that we 
  can safely decrease cache size if hit rate exceeds some user supplied 
  threshold (say .99995). 

<!-- NEW PAGE -->
<p>The hit rate threshold size decrement algorithm implemented in the 
  new metadata cache implements this intuition as follows:

<p>At the end of each epoch (this is the same epoch that is used in 
  the cache size increment algorithm), the hit rate is compared with 
  the user specified threshold.  If the hit rate exceeds that threshold, 
  the maximum cache size is decreased by a user specified factor.  If 
  required, the size of the reduction is clipped to stay within a user 
  specified lower bound, and optionally, within a user specified maximum 
  decrement.

<p>In my synthetic tests, this algorithm works poorly.  Even with a 
  very high threshold and a small maximum reduction, it results in 
  cache size oscillations.  The size increment code typically increments 
  cache size above the working set size.  This results in a high hit 
  rate, which causes the threshold size decrement code to reduce the 
  cache size below the working set size, which causes hit rate to crash 
  causing the cycle to repeat.  The resulting average hit rate is poor.

<p>It remains to be seen if this behavior will be seen in the field. 
  The algorithm is available for use, but it wouldn't be my first choice.
  
<h4>2.3.2.2 Ageout Cache Size Reduction:</h4>

<p>Another heuristic for dealing with oversized cache conditions is to 
  look for entries that haven't been accessed for a long time, evict 
  them, and reduce the cache size accordingly.

<p>The ageout cache size reduction applies this intuition as follows: 
  At the end of each epoch (again the same epoch as used in the cache 
  size increment algorithm), all entries that haven't been accessed for 
  a user configurable number of epochs (1 - 10 at present) are evicted. 
  The maximum cache size is then reduced to equal the sum of the sizes 
  of the remaining entries.  The size of the reduction is clipped to stay 
  within a user specified lower bound, and optionally, within a user 
  specified maximum decrement.

<p>In addition, the user may specify a minimum fraction of the cache 
  which must be empty before the cache size is reduced.  Thus if an 
  empty reserve of 0.1 was specified on a 10 MB cache, there would be no 
  cache size reduction unless the eviction of aged out entries resulted 
  in more than 1 MB of empty space.  Further, even after the reduction, 
  the cache would be one tenth empty.

<p>In my synthetic tests, the ageout algorithm works rather well, 
  although it is somewhat sensitive to the epoch length and ageout 
  period selection.

<h4>2.3.2.3 Ageout With Hit Rate Threshold Cache Size Reduction:</h4>

<p>To address these issues, I combined the hit rate threshold and 
  ageout heuristics.

<p>Ageout with threshold works just like ageout, save that the 
  algorithm is not run unless the hit rate exceeded a user specified 
  threshold in the previous epoch.

<p>In my synthetic tests, ageout with threshold seems to work 
  nicely, with no observed oscillation.  Thus I have selected it as the 
  default cache size reduction algorithm.

<p>For those interested in such things, the ageout algorithm is 
  implemented by inserting a marker entry at the head of the LRU 
  list at the beginning of each epoch.  Entries that haven't been 
  accessed for at least n epochs are simply entries that appear in 
  the LRU list after the n-th marker at the end of an epoch.

<h4>2.4 Configuring the New Metadata Cache:</h4>

<p>Due to lack of resources, the design work on the automatic cache 
  size adjustment algorithms was done hastily, using primarily synthetic 
  tests.  I don't think I spent more than a couple weeks writing and 
  running performance tests -- most time when into coding and 
  functional testing.

<p>As a result, while I think the algorithms provided for adaptive 
  cache resizing will work well in actual use, I don't really know. 
  Fortunately, the issue shouldn't arise for the vast majority of 
  HDF5 users, and those for whom it may arise should be savy enough to 
  recognize problems and deal with them.

<p>For this latter class of users, I have implemented a number of 
  new API calls allowing the user to select and configure the cache 
  resize algorithms, or to turn them off and control cache size 
  directly from the user program.  There are also API calls that 
  allow the user program to monitor hit rate and cache size.

<p>From the user perspective, all the cache configuration data is 
  contained in an instance of the <code>H5AC_cache_config_t</code> 
  structure -- the definition of which is given below:
  
<pre>
        typedef struct H5AC_cache_config_t
        {
            /* general configuration fields: */
            int                         version;

            hbool_t                     rpt_fcn_enabled;

            hbool_t                     set_initial_size;
            size_t                      initial_size;

            double                      min_clean_fraction;

            size_t                      max_size;
            size_t                      min_size;

            long int                    epoch_length;


            /* size increase control fields: */
            enum H5C_cache_incr_mode    incr_mode;

            double                      lower_hr_threshold;

            double                      increment;

            hbool_t                     apply_max_increment;
            size_t                      max_increment;


            /* size decrease control fields: */
            enum H5C_cache_decr_mode    decr_mode;

            double                      upper_hr_threshold;

            double                      decrement;

            hbool_t                     apply_max_decrement;
            size_t                      max_decrement;

            int                         epochs_before_eviction;

            hbool_t                     apply_empty_reserve;
            double                      empty_reserve;
			                            
			                            
			/* parallel configuration fields: */
			int                         dirty_bytes_threshold;			

        } H5AC_cache_config_t;
</pre>

<p>This structure is defined in <code>H5ACpublic.h</code>.  
  Each field is discussed in the associated header comment.

<p>The C API allows you get and set this structure directly.  
  Unfortunately the Fortran API has to do this with individual 
  parameters for each of the fields (with the exception of version).

<p>While the API calls are discussed individually in the reference 
  manual, an overall discussion of what fields to change for different 
  purposes should be useful.
  
<h4>2.4.1 General Configuration:</h4>

<p>The version field is intended to allow us to change the 
  <code>H5AC_cache_config_t</code> structure without breaking 
  old code.  For now, this field should always be set to 
  <code>H5AC__CURR_CACHE_CONFIG_VERSION</code>, even when you are 
  getting the current configuration data from the cache.  The library 
  needs the version number to know which fields are located where with 
  reference to the supplied base address.

<p>The <code>rpt_fcn_enabled</code> field is a boolean flag that 
  allows you to turn on and off the resize reporting function that 
  reports the activities of the adaptive cache resize code at the end 
  of each epoch -- assuming that it is enabled.

<p>The report function is unsupported, so you are on your own if you use 
  it.  Since it dumps status data to stdout, you should not attempt to use 
  it with Windows unless you modify the source.  You may find it useful if 
  you want to experiment with different adaptive resize configurations. 
  It is also a convenient way of diagnosing poor cache configuration. 
  Finally, if you do lots of runs with identical behavior, you can use it 
  to determine the metadata cache size needed in each phase of your 
  program so you can set the required cache sizes manually.
  
<p>As might be expected, the <code>max_size</code> and <code>min_size</code> 
  fields specify the range of maximum sizes that may be set for the cache.  
  <code>min_size</code> must be less than or equal to <code>max_size</code>, 
  and both must lie in the range [<code>H5C__MIN_MAX_CACHE_SIZE</code>, 
  <code>H5C__MAX_MAX_CACHE_SIZE</code>] -- currently [1 KB, 128 MB].  If you 
  routinely run a cache size in the top half of this range, you should increase 
  the hash table size.

<p>The <code>set_initial_size</code> and <code>initial_size</code> fields 
  allow you to specify an initial cache size.  If <code>set_initial_size</code> 
  is TRUE, <code>initial_size</code> must lie in the interval [<code>min_size</code>, 
  <code>max_size</code>]. If you disable the adaptive cache resizing code 
  (done by setting <code>incr_mode</code> to <code>H5C_incr__off</code> and 
  <code>decr_mode</code> to <code>H5C_decr__off</code>), you can use these fields 
  to control cache size manually.

<p>The <code>min_clean_fraction</code> sets the current minimum 
  clean size as a fraction of the current max cache size.  This 
  field is only used in the parallel version of the library, and must 
  lie in the range [0.0, 1.0].  0.25 is a reasonable value.
  
<p>The epoch_length is the number of cache accesses between runs 
  of the adaptive cache size control algorithms.  It is ignored 
  if these algorithms are turned off.  It must lie in the range 
  [<code>H5C__MIN_AR_EPOCH_LENGTH</code>, 
  <code>H5C__MAX_AR_EPOCH_LENGTH</code>] -- currently [100, 1000000].  
  The above constants are defined in <code>H5Cprivate.h</code>.  
  50000 is a reasonable value.

<h4>2.4.2 Increment Configuration:</h4>

<p><code>incr_mode</code> specifies the cache size increment 
  algorithm used. Its value must be a member of the 
  <code>H5C_cache_incr_mode</code> enum type -- currently either 
  <code>H5C_incr__off</code> or <code>H5C_incr__threshold</code>. 
  This type is defined in <code>H5Cpublic.h</code>

<p>If <code>incr_mode</code> is set to <code>H5C_incr__off</code>, 
  automatic cache size increases are disabled, and the remaining 
  fields in the cache size increase control section are ignored.
  
<h4>2.4.2.1 Hit Rate Threshold Cache Size Increase Configuration:</h4>

<p>If <code>incr_mode</code> is <code>H5C_incr__threshold</code>, 
  the cache size is increased via the hit rate threshold algorithm.  
  The remaining fields in the section are then used as follows:

<p><code>lower_hr_threshold</code> is the threshold below which hit 
  rate must fall to trigger an increase.  The value must lie in the 
  range [0.0 - 1.0].  In my tests, a relatively high value seems to 
  work best -- 0.9 for example.

<p><code>increment</code> is the factor by which the old maximum cache 
  size is multiplied to obtain an initial new maximum cache size when 
  an increment is needed.  The actual change in size may be smaller 
  as required by <code>max_size</code> and <code>max_increment</code> 
  (discussed below).  increment must be greater than or equal to 1.0.  
  If you set it to 1.0, you will effectively turn off the increment 
  code. 2.0 is a reasonable value.

<p><code>apply_max_increment</code> and <code>max_increment</code> allow 
  the user to specify a maximum increment.  If <code>apply_max_increment</code> 
  is TRUE, the cache size will never be increased by more than the number of 
  bytes specified in <code>max_increment</code> in any single increase.
  
<h4>2.4.3 Decrement Configuration:</h4>

<p><code>decr_mode</code> specifies the cache size decrement algorithm used.
  Its value must be a member of the <code>H5C_cache_decr_mode enum</code> 
  type -- currently either <code>H5C_decr__off</code>, 
  <code>H5C_decr__threshold</code>, <code>H5C_decr__age_out</code>, or 
  <code>H5C_decr__age_out_with_threshold</code>.  This type is defined in 
  <code>H5Cpublic.h</code>

<p>If <code>decr_mode</code> is set to <code>H5C_decr__off</code>, automatic 
  cache size decreases are disabled, and the remaining fields in the cache 
  size decrease control section are ignored.
  
<h4>2.4.3.1 Hit Rate Threshold Cache Size Decrease Configuration:</h4>

<p>if <code>decr_mode</code> is <code>H5C_decr__threshold</code>, the 
  cache size is decreased by the threshold algorithm, and the remaining 
  fields of decrement section are used as follows:

<p><code>upper_hr_threshold</code> is the threshold above which the hit 
  rate must fall to trigger cache size reduction.  It must be in the 
  range [0.0, 1.0].  In my synthetic tests, very high values like .9995 
  or .99995 seemed to work best.

<p><code>decrement</code> is the factor by which the current maximum 
  cache size is multiplied to obtain a tentative new maximum cache 
  size.  It must lie in the range [0.0, 1.0].  Relatively large values 
  like .9 seem to work best in my synthetic tests.  Note that the actual 
  size reduction may be smaller as required by <code>min_size</code> and 
  <code>max_decrement</code> (discussed below).

<!-- NEW PAGE -->
<p><code>apply_max_decrement</code> and <code>max_decrement</code> 
  allow the user to specify a maximum decrement.  If 
  <code>apply_max_decrement</code> is TRUE, cache size will never 
  be reduced by more than <code>max_decrement</code> bytes in any 
  single reduction.

<p>With the hit rate threshold cache size decrement algorithm, 
  the remaining fields in the section are ignored.
  
<h4>2.4.3.2 Ageout Cache Size Reduction:</h4>

<p>if <code>decr_mode</code> is <code>H5C_decr__age_out</code> 
  the cache size is decreased by the ageout algorithm, and the 
  remaining fields of decrement section are used as follows:

<p><code>epochs_before_eviction</code> is the number of epochs 
  an entry must reside unaccessed in the cache before it is 
  evicted. This value must lie in the range [<code>1</code>, 
  <code>H5C__MAX_EPOCH_MARKERS</code>]. 
  <code>H5C__MAX_EPOCH_MARKERS</code> is defined in 
  <code>H5Cprivate.h</code>, and is currently set to 10.

<p><code>apply_max_decrement</code> and <code>max_decrement</code> 
  are used as above.

<p><code>apply_empty_reserve</code> and <code>empty_reserve</code> 
  allow the user to specify a minimum empty reserve as discussed 
  in section 4.2.2.  An empty reserve of 0.05 or 0.1 seems to work 
  well.

<p>The <code>decrement</code> and <code>upper_hr_threshold</code> 
  fields are ignored in this case.

<h4>2.4.3.3 Ageout With Hit Rate Threshold Cache Size Reduction:</h4>

<p>If <code>decr_mode</code> is <code>H5C_decr__age_out_with_threshold</code>, 
  the cache size is decreased by the ageout with hit rate threshold 
  algorithm, and the fields of decrement section are used as per 
  the Ageout algorithm with the exception of <code>upper_hr_threshold</code>.

<p>Here, <code>upper_hr_threshold</code> is the threshold above 
  which the hit rate must fall to trigger cache size reduction.  
  It must be in the range [0.0, 1.0].  In my synthetic tests, high 
  values like .999 seemed to work well.

<h4>2.4.4 Parallel Configuration</h4>

<p>This section is a catch-all for parallel specific
  configuration data.  At present, it has only one field 
  -- <code>dirty_bytes_threshold</code>.

<p>In PHDF5, all operations that modify metadata must be
  executed collectively.  We used to think that this was
  enough to ensure consistency across the metadata caches, 
  but since we allow processes to read metadata individually, 
  the order of dirty entries in the LRU list can vary across
  processes, which can result in inconsistencies between the
  caches.

<p>To prevent this, only the metadata cache on process 0 of
  the file communicator is allowed to write to file, and then
  only after synchronizing with the other caches.  After it
  writes entries to file, it sends the base addresses of the
  now clean entries to the other caches, so they can mark these
  entries clean as well.

<p>The different caches know when to synchronize by counting
  the number of bytes of dirty metadata created by the
  collective operations modifying metadata.  Whenever this count
  exceeds the value specified in the <code>dirty_bytes_threshold</code>,
  process 0 flushes down to its minimum clean size, and then
  sends the list of newly cleaned entries to the other caches.

<p>Needless to say, the value of the <code>dirty_bytes_threshold</code>
  field must be consistant across all the caches operating on
  a given file.

<h4>2.4.5 Interactions:</h4>

<p>At present there is only one interaction between the increment 
  and decrement sections of the configuration.

<p>If <code>incr_mode</code> is <code>H5C_incr__threshold</code>, 
  and <code>decr_mode</code> is either <code>H5C_decr__threshold</code> 
  or <code>H5C_decr__age_out_with_threshold,</code> then 
  <code>lower_hr_threshold</code> must be strictly less than 
  <code>upper_hr_threshold</code>.
  
<h4>2.4.6  Default Configuration:</h4>

<p>At present, the default configuration for the new metadata 
  cache is as follows:
  
<pre>
{
  /* int         version                = */ H5C__CURR_AUTO_SIZE_CTL_VER,
  /* hbool_t     rpt_fcn_enabled        = */ FALSE,
  /* hbool_t     set_initial_size       = */ TRUE,
  /* size_t      initial_size           = */ (1 * 1024 * 1024),
  /* double      min_clean_fraction     = */ 0.5,
  /* size_t      max_size               = */ (16 * 1024 * 1024),
  /* size_t      min_size               = */ ( 1 * 1024 * 1024),
  /* long int    epoch_length           = */ 50000,
  /* enum H5C_cache_incr_mode incr_mode = */ H5C_incr__threshold,
  /* double      lower_hr_threshold     = */ 0.9,
  /* double      increment              = */ 2.0,
  /* hbool_t     apply_max_increment    = */ TRUE,
  /* size_t      max_increment          = */ (4 * 1024 * 1024),
  /* enum H5C_cache_decr_mode decr_mode = */ H5C_decr__age_out_with_threshold,
  /* double      upper_hr_threshold     = */ 0.999,
  /* double      decrement              = */ 0.9,
  /* hbool_t     apply_max_decrement    = */ TRUE,
  /* size_t      max_decrement          = */ (1 * 1024 * 1024),
  /* int         epochs_before_eviction = */ 3,
  /* hbool_t     apply_empty_reserve    = */ TRUE,
  /* double      empty_reserve          = */ 0.1,
  /* int         dirty_bytes_threshold  = */ (256 * 1024)
}
</pre>

<p>This configuration should be adequate for most HDF5 users. 
  Outside of synthetic tests, I have only seen the cache increase 
  beyond 1 MB on a few occasions, and never beyond 8 MB.

<p>Should you need to change it, it can be found in 
  <code>H5ACprivate.h</code>. Look for the definition of 
  <code>H5AC__DEFAULT_RESIZE_CONFIG</code>.
  
<h4>2.5 New Metadata Cache Debugging Facilities:</h4>

<p>The new metadata cache has a variety of debugging facilities 
  that may be of use.  I doubt that any other than the report function 
  will ever be accessible via the API, but they are relatively easy to 
  turn on in the source code.

<p>Note that none of this should be viewed as supported -- it is 
  described here on the off chance that you want to use it, but you are 
  on your own if you do.  Also, there are no promises as to consistency 
  between versions.

<p>As mentioned above, you can use the <code>rpt_fcn_enabled</code> 
  field of the configuration structure to enable the default reporting 
  function (<code>H5C_def_auto_resize_rpt_fcn()</code> in <code>H5C.c</code>).  
  If this function doesn't work for you, you will have to write your own.  
  In particular, remember that it uses <code>stdout</code>, so it will 
  probably be unhappy under Windows.

<p>Again, remember that this facility is not supported.  Further, 
  it is likely to change every time I do any serious work on the cache.

<p>There is also extensive stats collection code.  Use 
  <code>H5C_COLLECT_CACHE_STATS</code> and 
  <code>H5C_COLLECT_CACHE_ENTRY_STATS</code> in <code>H5Cprivate.h</code> 
  to turn this on.  If you also turn on <code>H5AC_DUMP_STATS_ON_CLOSE</code> 
  in <code>H5ACprivate.h</code>, stats will be dumped when you close a file.  
  Alternatively you can call <code>H5C_stats()</code> and 
  <code>H5C_stats__reset()</code> within the library to dump and reset stats. 
  Both of these functions are defined in <code>H5C.c</code>

<p>Finally, the cache also contains extensive sanity checking 
  code.  Much of this is turned on when you compile in debug mode, 
  but to enable the full suite, turn on <code>H5C_DO_SANITY_CHECKS</code> 
  in <code>H5Cprivate.h</code>
  
<h4>2.6 Controlling the New Metadata Cache Size From Your Program:</h4>

<p>You have already seen how <code>H5AC_cache_config_t</code> 
  has facilities that allow you to control the metadata cache 
  size directly.  Use <code>H5Fget_mdc_config()</code> and 
  <code>H5Fset_mdc_config()</code> to get and set the metadata 
  cache configuration on an open file.  Use <code>H5Pget_mdc_config()</code> 
  and <code>H5Pset_mdc_config()</code> to get and set the initial 
  metadata cache configuration in a file access property list.  Recall 
  that this list contains configuration data used when opening a file.

<p>Use <code>H5Fget_mdc_hit_rate()</code> to get the average hit rate 
  since the last time the hit rate stats were reset.  This happens 
  automatically at the beginning of each epoch if the adaptive cache 
  resize code is enabled.  You can also do it manually with 
  <code>H5Freset_mdc_hit_rate_stats()</code>. Be careful about doing 
  this if the adaptive cache resize code is enabled, as you may 
  confuse it.

<p>Use <code>H5Fget_mdc_size()</code> to get metadata cache size 
  data on an open file.

<p>Finally, note that cache size and cache footprint are two different 
  things -- in my tests, the cache footprint (as inferred from top) is 
  typically about three times the maximum cache size.  I haven't tracked 
  it down yet, but I would guess that most of this is due to the very 
  small typical cache entry size.  This should be investigated further, 
  but that will take time.
  
<h4>2.7 Trouble Shooting</h4>

<p>Absent major bugs in the cache, the only trouble shooting you 
  should have to do is diagnosing and fixing problems with your cache 
  configuration.

<p>Assuming it runs on your platform (I've only used it under Linux), 
  the reporting function is probably the most convenient diagnosis tool. 
  However, since it is unsupported code, I will not discuss it further 
  beyond directing you to the source (<code>H5C_def_auto_resize_rpt_fcn()</code> 
  in <code>H5C.c</code>).

<p>Absent the reporting function, regular calls to 
  <code>H5Fget_mdc_hit_rate()</code> should give you a good idea of 
  hit rate over time.  Remember that the hit rate stats are reset at 
  the end of each epoch (when adaptive cache resizing is enabled), 
  so you should expect some jitter.

<p>Similar calls to <code>H5Fget_mdc_size()</code> should 
  allow you to monitor cache size, and the fraction of the 
  cache that is actually in use.

<p>If the hit rate is consistently low, and the cache it at its 
  maximum size, increasing the maximum size is an obvious fix.

<p>If you see hit rate and cache size oscillations, try disabling 
  adaptive cache resizing and setting a fixed cache size a bit greater 
  than the high end of the cache size oscillations you observed. 

<p>If the hit rate oscillations don't go away, you are probably looking 
  at a feature of your application which can't be helped without major 
  changes to the cache.  Please send along a description of the situation.

<p>If they do, you may be able to come up with a configuration that 
  deals with the situation.  If that fails, control cache size manually, 
  and write me, so I can try to develop an adaptive resize algorithm 
  that works in your case.

<p>Needless to say, you should give the cache a few epochs to adapt 
  to circumstances.  If that is too slow for you, try manual cache 
  size control.
  
</body>
</html>

